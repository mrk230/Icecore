{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size x_train 1103\n",
      "size x_test 368\n",
      "size inc train 1103\n",
      "size inc test 368\n",
      "size y_train 1103\n",
      "size y_test 368\n",
      "size x full 1471\n",
      "size y full 1471\n",
      "size inc full 1471\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Dropout, concatenate\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "training_path = \"../../Test_data/train.json\"\n",
    "testing_path = \"../../Test_data/test.json\"\n",
    "\n",
    "train_data = pd.read_json(training_path)\n",
    "test_data = pd.read_json(testing_path)\n",
    "\n",
    "\n",
    "# no third for inc angle\n",
    "def get_scaled_imgs(df):\n",
    "    imgs = []\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        #make 75x75 image\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        band_3 = band_1 + band_2 # plus since log(x*y) = log(x) + log(y)\n",
    "        \n",
    "        # Rescale\n",
    "        # a = (band_1 - band_1.mean()) / (band_1.max() - band_1.min())\n",
    "        # b = (band_2 - band_2.mean()) / (band_2.max() - band_2.min())\n",
    "        # c = (band_3 - band_3.mean()) / (band_3.max() - band_3.min())\n",
    "\n",
    "        imgs.append(np.dstack((band_1, band_2, band_3)))    # , c)))\n",
    "\n",
    "    return np.array(imgs)\n",
    "\n",
    "X_orig = get_scaled_imgs(train_data)\n",
    "\n",
    "# resize to 150x150\n",
    "X = []\n",
    "for i in X_orig:\n",
    "    X.append(cv2.resize(i, (150,150)))\n",
    "X = np.array(X)\n",
    "\n",
    "# get only data that has a non 0 inc angle\n",
    "train_data.inc_angle = train_data.inc_angle.replace('na',0)\n",
    "idx_tr = np.where(train_data.inc_angle>0)\n",
    "\n",
    "Y = train_data[\"is_iceberg\"]\n",
    "inc_angle = train_data[\"inc_angle\"]\n",
    "\n",
    "Y_inc = Y[idx_tr[0]]\n",
    "X_inc = X[idx_tr[0],...]\n",
    "inc_angle_inc = inc_angle[idx_tr[0]]\n",
    "# inc_angle_norm = (inc_angle_inc - inc_angle_inc.mean()) / (inc_angle_inc.max() - inc_angle_inc.min())\n",
    "\n",
    "\n",
    "X_full = X_inc\n",
    "Y_full = Y_inc\n",
    "inc_full = inc_angle_inc\n",
    "\n",
    "X_train, X_test, y_train, y_test, inc_train, inc_test = train_test_split(X_inc, Y_inc,\n",
    "                                                    inc_angle_inc, test_size = 0.25, \n",
    "                                                                         random_state=42)\n",
    "\n",
    "print(\"size x_train\", len(X_train))\n",
    "print(\"size x_test\", len(X_test))\n",
    "print(\"size inc train\", len(inc_train))\n",
    "print(\"size inc test\", len(inc_test))\n",
    "print(\"size y_train\", len(y_train))\n",
    "print(\"size y_test\", len(y_test))\n",
    "\n",
    "print(\"size x full\", len(X_full))\n",
    "print(\"size y full\", len(Y_full))\n",
    "print(\"size inc full\", len(inc_full))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiled\n"
     ]
    }
   ],
   "source": [
    "# this could also be the output a different Keras model or layer\n",
    "from keras.layers import Flatten\n",
    "\n",
    "input_tensor = Input(shape=(150, 150, 3))\n",
    "ang_input = Input(shape=(1,))\n",
    "\n",
    "base_model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# concat the angle\n",
    "x = concatenate([x, ang_input])\n",
    "\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, kernel_regularizer=regularizers.l2(.1),\n",
    "          bias_regularizer=regularizers.l2(.1))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, kernel_regularizer=regularizers.l2(.1),\n",
    "          bias_regularizer=regularizers.l2(.1))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=[base_model.input ,ang_input], outputs=predictions)\n",
    "\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer=Adam(lr=0.00001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "print(\"compiled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "46/45 [==============================] - 12s 257ms/step - loss: 237.9175 - acc: 0.4745\n",
      "Epoch 2/20\n",
      "46/45 [==============================] - 10s 225ms/step - loss: 233.0372 - acc: 0.4949\n",
      "Epoch 3/20\n",
      "46/45 [==============================] - 10s 227ms/step - loss: 228.3007 - acc: 0.5064\n",
      "Epoch 4/20\n",
      "46/45 [==============================] - 11s 238ms/step - loss: 223.7342 - acc: 0.5098\n",
      "Epoch 5/20\n",
      "46/45 [==============================] - 10s 227ms/step - loss: 219.1571 - acc: 0.5051\n",
      "Epoch 6/20\n",
      "46/45 [==============================] - 11s 239ms/step - loss: 214.6141 - acc: 0.5275\n",
      "Epoch 7/20\n",
      "46/45 [==============================] - 11s 237ms/step - loss: 210.1372 - acc: 0.5445\n",
      "Epoch 8/20\n",
      "46/45 [==============================] - 11s 233ms/step - loss: 205.7727 - acc: 0.5283\n",
      "Epoch 9/20\n",
      "46/45 [==============================] - 11s 233ms/step - loss: 201.5310 - acc: 0.5296\n",
      "Epoch 10/20\n",
      "46/45 [==============================] - 11s 234ms/step - loss: 197.2895 - acc: 0.5459\n",
      "Epoch 11/20\n",
      "46/45 [==============================] - 11s 235ms/step - loss: 193.0071 - acc: 0.5752\n",
      "Epoch 12/20\n",
      "46/45 [==============================] - 11s 236ms/step - loss: 188.9786 - acc: 0.5534\n",
      "Epoch 13/20\n",
      "46/45 [==============================] - 11s 230ms/step - loss: 184.9154 - acc: 0.5588\n",
      "Epoch 14/20\n",
      "46/45 [==============================] - 11s 236ms/step - loss: 181.0441 - acc: 0.5248\n",
      "Epoch 15/20\n",
      "46/45 [==============================] - 11s 237ms/step - loss: 177.1143 - acc: 0.5500\n",
      "Epoch 16/20\n",
      "46/45 [==============================] - 11s 236ms/step - loss: 173.2927 - acc: 0.5452\n",
      "Epoch 17/20\n",
      "46/45 [==============================] - 11s 233ms/step - loss: 169.5136 - acc: 0.5533\n",
      "Epoch 18/20\n",
      "46/45 [==============================] - 11s 232ms/step - loss: 165.8168 - acc: 0.5546\n",
      "Epoch 19/20\n",
      "46/45 [==============================] - 11s 238ms/step - loss: 162.1880 - acc: 0.5521\n",
      "Epoch 20/20\n",
      "46/45 [==============================] - 11s 234ms/step - loss: 158.5948 - acc: 0.5724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7477c6bc18>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model on the new data for a few epochs, just to get the top layer going\n",
    "\n",
    "# training code\n",
    "#%% Image data augmentation \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import random\n",
    "\n",
    "\n",
    "def generator_multiple(generator, X, inc_angle, y, batch_size):\n",
    "    # shuffle initially (per epoch)\n",
    "    shuff = list(zip(X, inc_angle, y))\n",
    "    random.shuffle(shuff)\n",
    "    X_shuff, inc_shuff, y_shuff = zip(*shuff)\n",
    "    \n",
    "    X_shuff = np.asarray(X_shuff)\n",
    "    inc_shuff = np.asarray(inc_shuff)\n",
    "    y_shuff = np.asarray(y_shuff)\n",
    "    \n",
    "        \n",
    "    genX1 = generator.flow(X_shuff, y_shuff, shuffle=False, batch_size = batch_size)\n",
    "    genX2 = generator.flow(X_shuff, inc_shuff, shuffle=False, batch_size = batch_size)\n",
    "    \n",
    "    while True:\n",
    "        X1i = genX1.next()\n",
    "        X2i = genX2.next()\n",
    "        \n",
    "        yield [X1i[0], X2i[1]], X1i[1]\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,               # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,                # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,    # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,     # divide each input by its std\n",
    "    zca_whitening=False,                    # apply ZCA whitening\n",
    "    rotation_range=0,                      # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.3,                  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.3,                 # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,                   # randomly flip images\n",
    "    vertical_flip=False,                   # randomly flip images\n",
    "    zoom_range=0.2)                     \n",
    "\n",
    "datagen.fit(X_train)\n",
    "model.fit_generator(generator_multiple(datagen, X_full, inc_full, Y_full, batch_size=32),\n",
    "                    steps_per_epoch = len(X_full)/32.0, epochs = 20,\n",
    "                     verbose= 1) #, validation_data = ([X_test,inc_test], y_test))   # validation_data = (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recompiled\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:1]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[1:]:\n",
    "   layer.trainable = True\n",
    "# training them all\n",
    "#for layer in model.layers:\n",
    "#    layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.00001), loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "def get_callbacks(filepath, patience=2):\n",
    "    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [es, msave]\n",
    "file_path = \"model_weights_transf_inc_incV3.hdf5\"\n",
    "callbacks = get_callbacks(filepath=file_path, patience=15)\n",
    "\n",
    "print(\"recompiled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "46/45 [==============================] - 30s 648ms/step - loss: 154.8756 - acc: 0.5826\n",
      "Epoch 2/45\n",
      "46/45 [==============================] - 21s 466ms/step - loss: 150.9190 - acc: 0.6112\n",
      "Epoch 3/45\n",
      "46/45 [==============================] - 21s 465ms/step - loss: 146.9581 - acc: 0.6513\n",
      "Epoch 4/45\n",
      "46/45 [==============================] - 21s 466ms/step - loss: 143.1627 - acc: 0.6676\n",
      "Epoch 5/45\n",
      "46/45 [==============================] - 21s 466ms/step - loss: 139.4065 - acc: 0.6704\n",
      "Epoch 6/45\n",
      "46/45 [==============================] - 21s 465ms/step - loss: 135.7279 - acc: 0.6833\n",
      "Epoch 7/45\n",
      "46/45 [==============================] - 21s 466ms/step - loss: 132.1165 - acc: 0.7151\n",
      "Epoch 8/45\n",
      "46/45 [==============================] - 21s 465ms/step - loss: 128.5505 - acc: 0.7234\n",
      "Epoch 9/45\n",
      "46/45 [==============================] - 21s 466ms/step - loss: 125.0406 - acc: 0.7430\n",
      "Epoch 10/45\n",
      "46/45 [==============================] - 21s 467ms/step - loss: 121.6208 - acc: 0.7675\n",
      "Epoch 11/45\n",
      "46/45 [==============================] - 21s 467ms/step - loss: 118.2800 - acc: 0.7708\n",
      "Epoch 12/45\n",
      "46/45 [==============================] - 21s 466ms/step - loss: 115.0078 - acc: 0.7717\n",
      "Epoch 13/45\n",
      "46/45 [==============================] - 21s 466ms/step - loss: 111.7963 - acc: 0.7818\n",
      "Epoch 14/45\n",
      "46/45 [==============================] - 21s 467ms/step - loss: 108.6541 - acc: 0.7933\n",
      "Epoch 15/45\n",
      "46/45 [==============================] - 21s 466ms/step - loss: 105.5520 - acc: 0.8225\n",
      "Epoch 16/45\n",
      "46/45 [==============================] - 21s 466ms/step - loss: 102.5799 - acc: 0.8068\n",
      "Epoch 17/45\n",
      "46/45 [==============================] - 21s 465ms/step - loss: 99.6341 - acc: 0.8219\n",
      "Epoch 18/45\n",
      "46/45 [==============================] - 21s 466ms/step - loss: 96.7474 - acc: 0.8307\n",
      "Epoch 19/45\n",
      "46/45 [==============================] - 21s 465ms/step - loss: 93.9449 - acc: 0.8280\n",
      "Epoch 20/45\n",
      "46/45 [==============================] - 21s 465ms/step - loss: 91.2084 - acc: 0.8308\n",
      "Epoch 21/45\n",
      "46/45 [==============================] - 21s 465ms/step - loss: 88.5174 - acc: 0.8545\n",
      "Epoch 22/45\n",
      "46/45 [==============================] - 21s 466ms/step - loss: 85.9109 - acc: 0.8464\n",
      "Epoch 23/45\n",
      "46/45 [==============================] - 21s 467ms/step - loss: 83.3785 - acc: 0.8490\n",
      "Epoch 24/45\n",
      "46/45 [==============================] - 21s 466ms/step - loss: 80.8910 - acc: 0.8539\n",
      "Epoch 25/45\n",
      "46/45 [==============================] - 21s 466ms/step - loss: 78.4599 - acc: 0.8579\n",
      "Epoch 26/45\n",
      "46/45 [==============================] - 21s 465ms/step - loss: 76.0930 - acc: 0.8579\n",
      "Epoch 27/45\n",
      "46/45 [==============================] - 21s 465ms/step - loss: 73.7913 - acc: 0.8749\n",
      "Epoch 28/45\n",
      "46/45 [==============================] - 21s 465ms/step - loss: 71.5480 - acc: 0.8606\n",
      "Epoch 29/45\n",
      "46/45 [==============================] - 21s 466ms/step - loss: 69.3602 - acc: 0.8722\n",
      "Epoch 30/45\n",
      "46/45 [==============================] - 21s 465ms/step - loss: 67.2377 - acc: 0.8688\n",
      "Epoch 31/45\n",
      "46/45 [==============================] - 21s 466ms/step - loss: 65.1477 - acc: 0.8648\n",
      "Epoch 32/45\n",
      "46/45 [==============================] - 21s 465ms/step - loss: 63.1107 - acc: 0.8668\n",
      "Epoch 33/45\n",
      "46/45 [==============================] - 21s 465ms/step - loss: 61.1426 - acc: 0.8789\n",
      "Epoch 34/45\n",
      "46/45 [==============================] - 21s 466ms/step - loss: 59.2144 - acc: 0.8919\n",
      "Epoch 35/45\n",
      "46/45 [==============================] - 21s 465ms/step - loss: 57.3621 - acc: 0.8817\n",
      "Epoch 36/45\n",
      "46/45 [==============================] - 21s 465ms/step - loss: 55.5327 - acc: 0.8872\n",
      "Epoch 37/45\n",
      "46/45 [==============================] - 21s 466ms/step - loss: 53.7701 - acc: 0.8831\n",
      "Epoch 38/45\n",
      "46/45 [==============================] - 21s 465ms/step - loss: 52.0488 - acc: 0.8878\n",
      "Epoch 39/45\n",
      "46/45 [==============================] - 21s 465ms/step - loss: 50.3769 - acc: 0.8886\n",
      "Epoch 40/45\n",
      "46/45 [==============================] - 21s 466ms/step - loss: 48.7537 - acc: 0.8960\n",
      "Epoch 41/45\n",
      "46/45 [==============================] - 21s 465ms/step - loss: 47.1711 - acc: 0.8953\n",
      "Epoch 42/45\n",
      "46/45 [==============================] - 21s 465ms/step - loss: 45.6331 - acc: 0.8912\n",
      "Epoch 43/45\n",
      "46/45 [==============================] - 21s 466ms/step - loss: 44.1423 - acc: 0.8980\n",
      "Epoch 44/45\n",
      "46/45 [==============================] - 21s 465ms/step - loss: 42.6810 - acc: 0.9000\n",
      "Epoch 45/45\n",
      "46/45 [==============================] - 21s 465ms/step - loss: 41.2567 - acc: 0.9082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7494b65fd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "# train the model on the new data for a few epochs, just to get the top layer going\n",
    "\n",
    "# training code\n",
    "#%% Image data augmentation \n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "#datagen = ImageDataGenerator(\n",
    "#    featurewise_center=False,               # set input mean to 0 over the dataset\n",
    "#    samplewise_center=False,                # set each sample mean to 0\n",
    "#    featurewise_std_normalization=False,    # divide inputs by std of the dataset\n",
    "#    samplewise_std_normalization=False,     # divide each input by its std\n",
    "#    zca_whitening=False,                    # apply ZCA whitening\n",
    "#    rotation_range=0,                      # randomly rotate images in the range (degrees, 0 to 180)\n",
    "#    width_shift_range=0.3,                  # randomly shift images horizontally (fraction of total width)\n",
    "#    height_shift_range=0.3,                 # randomly shift images vertically (fraction of total height)\n",
    "#    horizontal_flip=False,                   # randomly flip images\n",
    "#    vertical_flip=False,                   # randomly flip images\n",
    "#    zoom_range=0.1) \n",
    "\n",
    "datagen.fit(X_train)\n",
    "model.fit_generator(generator_multiple(datagen, X_full, inc_full, Y_full, batch_size=32),\n",
    "                    steps_per_epoch = len(X_full)/32.0, epochs = 45,\n",
    "                     verbose= 1) #, validation_data = ([X_test,inc_test], y_test))\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if doing no val set (i.e. final) only\n",
    "filepath_full = 'model_weights_transf_inc_incV3_full.hdf5'\n",
    "model.save(filepath_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of pred test 8424\n",
      "len of id 8424\n"
     ]
    }
   ],
   "source": [
    "# from above, need to see the amount of epochs (80 +) that val stops increasing at, then do \n",
    "# that in one full go and save the model\n",
    "\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "# if not using val\n",
    "file_path_use = filepath_full\n",
    "# if using val\n",
    "#file_path_use = file_path\n",
    "inf_model = load_model(file_path_use)\n",
    "\n",
    "#score = inf_model.evaluate(X_test, y_test, verbose=1)\n",
    "#print('Test loss:', score[0])\n",
    "#print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "X_orig_test = get_scaled_imgs(test_data)\n",
    "\n",
    "# resize to 150x150\n",
    "X_sub = []\n",
    "for i in X_orig_test:\n",
    "    X_sub.append(cv2.resize(i, (150,150)))\n",
    "X_sub = np.array(X_sub)\n",
    "inc_angle_t = test_data[\"inc_angle\"]\n",
    "\n",
    "\n",
    "predicted_test=inf_model.predict([X_sub, inc_angle_t])\n",
    "\n",
    "print(\"len of pred test\", len(predicted_test))\n",
    "print(\"len of id\", len(test_data['id']))\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test_data['id']\n",
    "submission['is_iceberg']=np.clip(predicted_test, 0.01, 0.99)\n",
    "submission.to_csv('sub_full_transfer_inc_incV3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
